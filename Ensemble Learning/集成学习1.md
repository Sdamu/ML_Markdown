# 集成学习

&emsp;&emsp; 集成学习（ensemble learning）通过构建并结合多个学习起来完成 学习任务，有时也被称为多分类器系统（multi-classifer system)、基于委员会的学习等等。

&emsp;&emsp;通过不同的方式来将多个分类器结合成为一个强分类器，具体可以分为“同质集成”和“异质集成”。其中，同质指的是最后构建的分类器系统仅仅由一种相同的 基分类器构成，而 异质 指的是最后构建的分类器系统由不仅一种基分类器构成，这时候基分类器一般也不叫基分类器，而是“组件学习器”。

&emsp;&emsp;需要说明的是，将一系列的若学习器结合在一起构成想要构成一个更强的学习器（分类器）也是有要求的，也就是说，想要获得好的集成，应当：

- 个体学习器应该有一定的 “准确性”
- 个体学习器之间应该有一定的 ”差异“

总的来说，就是要个体分类器之间做到 ”**好而不同**“。

&emsp;&emsp;但是，所有用来集成的个体学习器都是为了解决同一个问题训练得来的，因此它们显然不可能相互独立，事实上，个体学习器之间的 “准确性” 与 “多样性” 本身就存在着冲突。一般的，在准确性很高之后，想要增加多样性，就要牺牲一定的 准确性。



&emsp;&emsp;根据个体学习器的生成方式，目前的集成学习方法大致可以分成两大类：

1. 个体学习器之间存在前依赖关系，必须穿串行生成的序列化方法
2. 个体学习器之间不存在强依赖关系、可同时生成的并行化方法；

第一种的代表方法是 “boosting”，后面一中的代表方法是 “Bagging” 和 "随机森林"。



## 1. 结合策略

&emsp;&emsp;这部分参考[集成学习原理小结](http://www.cnblogs.com/pinard/p/6131423.html)

&emsp;&emsp;假设用来进行集成学习的几个分类器分别为 $\{h_1,h_2,...,h_m\}$

1. 平均结合法：

   &emsp;&emsp;对于数值类的回归问题，通常使用的结合策略是 平均法，也就是说，对于若干和若学习器的输出进行平均得到最终的预测输出。

   - 算术平均，即为：
     $$
     H(x)=\frac{1}{T}\sum_1^Th_i(x)
     $$

   - 加权结合，假设每个学习器有一个权重 $w$

   $$
   H(x)=\sum_{i=1}^Tw_ih_i(x)
   $$

   &emsp;&emsp;其中 $w_i$ 是个体学习器 $h_i$ 的权重，通常有：
   $$
   w_i\geq0,\ \ \ \sum_{i=1}^Tw_i=1
   $$

2. 投票法：

   &emsp;&emsp;对于分类问题的预测，我们通常使用的是投票法，假设我们的预测类别是 $\{c_1,c_2,...,c_k\}$，对于任意一个预测样本 $x$，我们的 $T$ 个若学习器的预测结果是 $\{h_1(x),h_2(x),...,h_T(x)\}$。

   &emsp;&emsp;a. 相对多数投票法，也就是我们常说的少数服从多数。如果最后不止一个类别获得了最高票数，则随机选择一个做最终的类别。

   &emsp;&emsp;b. 绝对多数投票法，也就是我们常说的票数必须要过半。在上面相对多数投票法的基础上，不光要求获得最高票数，同时要求票数必须过半，否则学习器会拒绝预测。

   &emsp;&emsp;c. 加权投票法，与健全平均法一样，每个若学习器的分类票数要乘以一个权重，最终将各个来别的加权票数进行求和，最大的值对应的类别为最重类别。

3. 学习法：

   &emsp;&emsp;上面的方法都是对弱学习器的结果做平均或者投票，相对比较简单，但是可能学习误差较大，于是就有了学习法这种方法，对于学习法，代表方法是stacking，当使用stacking的结合策略时， 我们不是对弱学习器的结果做简单的逻辑处理，而是 **再加上一层学习器**，也就是说，我们**将训练集弱学习器的学习结果作为输入，将训练集的输出作为输出，重新训练一个学习器来得到最终结果**。

   &emsp;&emsp;在这种情况下，我们将弱学习器称为初级学习器，将用于结合的学习器称为次级学习器。对于测试集，我们首先用初级学习器预测一次，得到次级学习器的输入样本，再用次级学习器预测一次，得到最终的预测结果。



## 2. Boosting

&emsp;&emsp;Boosting 算法是一族可以将若学习器提升为强学习器的算法。工作机制大致如下：

> - 首先从出事训练集训练出一个 及学习期。
> - 在根据基学习器的表现对训练样本进行调整，使得新签基学习器做错的训练样本在后续受到更多的关注
> - 基于调整后的样本分布来训练下一个基学习器
> - 如此冲进行，直到基学习器数目达到了事先指定的数目 $T$，最终将这 $T$ 个基学习器进行加权结合

上面的步骤中最后一个写到了 “进行加权结合”，这种加权结合是一种 平均结合方法。关于结合方法在上面已经进行了相关的介绍。



#### 2.1 Adaboost

&emsp;&emsp; 对于所有的 Boosting 算法来说，都有两个问题需要解答：

1. 在每一轮如何改变训练数据的权值或概率分布？
2. 如何将弱分类器组合成为一个强分类器？

关于问题一，Adaboost 的做法是：

> 提高那些前一轮被错误分类样本的权值，而降低那些前一轮被正确分类的样本的权值。

关于问题二，Adaboost 的做法是：

> 采用加权多数表决的方法。也就是说，加大分类误差率小的弱分类器的权值，使其在表决中起较大的作用，减小分类误差率大的弱分类器的权值，使其在表决中起比较小的作用。  



##### 2.1.1 Adaboost 算法

&emsp;&emsp;假设给定一个二分类的训练数据集：
$$
T=\{(x_1,y_1),(x_2,y_2)m,...,(x_N,y_N)\}
$$
其中，每个样本点由实例与标记组成。其中，实例 $x\in\mathcal{X}\subseteq \textbf{R}^n$，标记 $y\in\mathcal{Y}=\{-1,+1\}$，其中 $\mathcal{X}$ 是实例空间， $\mathcal{Y}$ 是标记集合。Adaboost 使用下面的算法，从训练数据中学习出一系列弱分类器或是基本分类器，并将这些弱分类器 **线性组合** 成为一个强分类器。

- 输入：训练数据集 $T=\{(x_1,y_1),(x_2,y_2)m,...,(x_N,y_N)\}$，其中 $x\in\mathcal{X}\subseteq \textbf{R}^n, y\in\mathcal{Y}=\{-1,+1\}$；弱学习算法；
- 输出：最终分类器 $G(x)$；

1. 初始化训练数据的权值分布：
   $$
   D_1=(w_{11},...,w_{1i},...,w_{1N}),\ \ \ \ \ w_{1i}=\frac{1}{N},\ \ \ i=1,2,..N
   $$

2. 对于 $m=1,2,...,M$

   - 使用具有权值分布 $D_m$ 的训练数据集学习，得到基本分类器：
     $$
     G_m(x):\mathcal{X}\rightarrow \{-1,+1\}
     $$

   - 计算 $G_m$ 在训练数据机上的分类误差率：

   $$
   e_m=P(G_m(x_i)\neq y_i)=\sum_{i=1}^Nw_{mi}I(G_m(x_i)\neq y_i)
   $$

   - 计算 $G_m(x)$ 的系数
     $$
     \alpha_m=\frac{1}{2}log\frac{1-e_m}{e_m}
     $$
     这里的对数指的是 自然对数，也就是 $ln$。

   - 更新训练数据集的权值分布：
     $$
     D_{m+1}=(w_{m+1,1},...,w_{m+1,i},...,w_{m+1,N})\\
     w_{m+1,i}=\frac{w_{mi}}{Z_m}exp(-\alpha_my_iG_m(x_i)),\ \ \ i=1,2,...,N
     $$
     这里 $Z_m$ 是规范化因子：
     $$
     Z_m = \sum_{i=1}^Nw_{mi}exp(-\alpha_my_iG_m(x_i))
     $$
     它的作用是使得 $D_{m+1}$ 成为一个概率分布

3. 构建基本分类器的线性组合

$$
f(x)=\sum_{m=1}^M\alpha_mG_m(x)
$$

从而进一步得到最终的分类器：
$$
G(x)=sign(f(x))=sign\left(\sum_{m=1}^M\alpha_mG_m(x)\right)
$$

##### 2.1.2 算法说明

&emsp;&emsp;**步骤 1**：假设悬链数据基友均匀的权值分布，也就是每个训练样本在基本分类器的学习中作用相同，这一假设保证了第一步能够在原始数据上学习基本分类器 $G_1(x)$。

&emsp;&emsp;**步骤 2**：Adaboost 反复学习基本分类器，在每一轮 $m=1,2,...,M$ 顺序地执行下面的操作：

- 使用当前分布 $D_m$ 加权的训练数据集，学习基本分类器 $G_m(x)$.

- 计算基本分类器 $G_m(x)$ 在加权训练数据集上的分类误差率：
  $$
  e_m=P(G_m(x_i)\neq y_i)=\sum_{G_m(x_i)\neq y_i}w_{mi}
  $$
  这里，$w_{mi}$ 表示第 $m$ 轮中第 $i$ 个实例的权值，$\sum_{i=1}^{N}w_{mi}=1$。这表明，$G_m$ 在加权的训练数据集上的分类误差率是被 $G_m(x)$ 误分类样本的权值之和，由此可以看出权值分布 $D_m$ 与基本分类器 $G_m(x)$ 的分类误差率的关系。

- 计算基本分类器 $G_m(x)$ 的系数 $\alpha_m$。这个 $\alpha_m$ 表示 $G_m(x)$ 在最终分类器中的重要性。由上面的表达式可以知道，当 $e_m<\frac{1}{2}$ 时，$\alpha_m \geq 0$。并且 $\alpha_m$ 随着 $e_m$ 的减小而增大，所以分类误差率越小的基本分类器在最终分类器中的作用越大。

  给出图像：

![微信图片_20180312200527](C:\Users\Damu\Desktop\微信图片_20180312200527.jpg)

- 更新训练数据的取值分布为下一轮做准备，上面的更新公式可以化简为：

$$
w_{m+1,i}=\left\{ \begin{align}
\frac{w_{mi}}{Z_m}e^{-\alpha_m},\ \ \ G_m(x_i)=y_i \\
\frac{w_{mi}}{Z_m}e^{\alpha_m},\ \ \ G_m(x_i)\neq y_i
\end{align}
\right.
$$

&emsp;&emsp;从上面这个公式可以看出，被基本分类器 $G_m(x)$ 误分类样本的权值得以扩大，而被正确分类样本的权值却得以缩小。两者相互比较，误分类样本的权值被放大了 $e^{2\alpha_m}=\frac{e_m}{1-e_m}$倍，因此，误分类样本在下一轮学习中会起到更大的作用。

&emsp;&emsp;不改变所给的训练数据，而不断改变训练数据权值的分布，使得训练数据在基本分类器的学习中起不同的作用，这也正是 $Adaboost$ 的一个特点。



&emsp;&emsp;**步骤 3**：线性组合 $f(x)$ 实现 $M$ 个基本分类器的加权表决。系数 $\alpha_m$ 表示了基本分类器 $G_m(x)$ 的重要性，这里，所有的 $\alpha_m$ 之和并不为 1。其中，$f(x)$ 的符号决定实例 $x$ 的类，$f(x)$ 的绝对值标识分类的确信度。利用基本分类器的线性组合构建最终分类器是 $Adaboost$ 的另一个特点。



##### 2.1.3 前向分步算法与 AdaBoost

&emsp;&emsp;由前向分步算法可以推导出 $Adaboost$，使用定理叙述这一关系。

&emsp;&emsp;**定理** ： Adaboost 算法是前向分步加法算法的特例。这时，模型是有基本分类器组成的加法模型，损失函数是指数函数。

&emsp;&emsp;**证明**： 前向分步算法学习的是加法模型，当基函数为基本分类器时，该加法模型等价于 $AdaBoost$ 的最终分类器：
$$
f(x)=\sum_{m=1}^N\alpha_mG_m(x)
$$
从上式可以看出，最终分类器是由基本分类器 $G_m(x)$ 以及其系数 $\alpha_m$ 组成的，其中，$m=1,2,...,M$

&emsp;&emsp;前向分步算法逐一学习基函数，这一过程与 Adaboost 算法逐一学习基本分类器的过程是一致的。下面给出证明，当前向分步算法的损失函数是**指数损失函数**的时候，其学习的具体操作等价于 $AdaBoost$ 算法学习的具体操作。其中，指数损失函数为：
$$
L(y,f(x))=exp[-yf(x)]
$$
&emsp;&emsp;假设经过 $m-1$ 轮的迭代前向分步算法已经得到了 $f_{m-1}(x)$:
$$
f_{m-1}(x)=\sum_{i=1}^{m-1}\alpha_iG_i(x)
$$
而第 $m$ 轮强学习器可以表述为：
$$
f_m(x)=\sum_{i=1}^m\alpha_iG_i(x)
$$
通过上面两个式子可以的得到：
$$
f_m(x)=f_{m-1}(x)\alpha_mG_m(x)
$$
学习的目标是使得前向分步算法得到的 $\alpha_m,G_m(x)$ 使得 $f_m(x)$ 在训练数据集 $T$ 上的指数损失最小，也就是有：
$$
(\alpha_m,G_m(x))=arg\ min_{\alpha,G}\sum_{i=1}^Nexp[-y_i(f_{m-1}x_i)+\alpha G(x_i)]
$$
上式可以表示为：
$$
(\alpha_m,G_m(x))=arg\ min_{\alpha,G}\sum_{i=1}^N\bar{w}_{mi}exp(-y_i\alpha G(x_i))
$$
其中，$\bar{w}_{mi}=exp(-y_if_{m-1}(x_i))$，因为这个项既不依赖 $\alpha$ 也不依赖 $G$，因此与最小化无关。但是 $\bar{w}_mi$ 依赖于 $f_{m-1}(x)$，会随着每一轮的迭代而改变。

&emsp;&emsp;因此现在就是要证明上式中能够达到最小的 $\alpha, G$ 就是 $Adaboost$ 算法所得到的 $\alpha_m,G_m(x)$。

- 首先，求 $G_m^*(x)$。对于任意的 $\alpha>0$，上式中最小的 $G(x)$ 由下面的式子得到：
  $$
  G_m^*(x)=arg\ min_G\sum_{i=1}^N\bar{w}_{mi}I(y_i\neq G(x_xi))
  $$
  其中，$\bar{w}_{mi}=exp[-y_if_{m-1}(x_i)]$

  这个分类器 $G_m^*(x)$ 也就是 $AdaBoost$ 算法的基本分类器 $G_m(x)$，因为它是使第 $m$ 轮家犬训练数据分类误差率最小的基本分类器

- 然后，求 $\alpha_m^*$。将上面 $G_m^*$ 的表达式带入到征途的损失中，可以得到：
  $$
  \sum_{i=1}^N\bar{w}_{mi}exp[-y_i\alpha G(x_i)]=\sum_{y=G_m(x_i)}\bar{w}_{mi}e^{-\alpha}+\sum_{y\neq G_m(x_i)}\bar{w}_{mi}e^{\alpha}\\
  =(e^{\alpha}-e^{-\alpha})\sum_{i=1}^N\bar{w}_{mi}I(y_i\neq G(x_i))+e^{-\alpha}\sum_{i=1}^N\bar{w}_{mi}
  $$

- 上式对 $\alpha$ 进行求导可得：
  $$
  \alpha_m^*=\frac{1}{2}log\frac{1-e_m}{e_m}
  $$
  其中，$e_m$ 是分类误差率：
  $$
  e_m=\frac{\sum_{i=1}^N\bar{w}_{mi}I(y_i\neq G_m(x_i))}{\sum_{i=1}^{N}\bar{w}_{mi}}=\sum_{i=1}^Nw_{mi}I(y_i\neq G_m(x_i))
  $$
  可以看到，这里的 $\alpha_m^*$ 与 Adaboost 算法中的 更新权重完全相同。



##### 2.1.4 AdaBoost 算法的正则化

&emsp;&emsp;为了防止 Adaboost 算法的过拟合，通常情况下也会增加正则化项，这个正则化项我们通常称为 **步长（learning rate）**。定义为 $\mathcal{v}$，对于前面的若学习期的迭代：
$$
f_k(x)=f_{k-1}(x)+\alpha_kG_k(x)
$$
如果我们增加了正则化项，则有：
$$
f_k(x)=f_{k-1}(x)+\mathcal{v}\alpha_kG_k(x)
$$
其中， $\mathcal{v}$ 的取值范围是 $0<\mathcal{v}<1$。对于同样的训练集学习效果，较小的 $\mathcal{v}$ 意味着我们需要更多地弱学习器的迭代次数。通常我们使用补偿和迭代最大次数一起来决定算法的拟合效果。



##### 2.1.5 Adaboost 总结

 &emsp;&emsp;这里需要说明，构成 Adaboost 的若学习器的理论上可以使用任何学习器。但是一般来说，使用最广泛的 Adaboost 若学习器是决策树和神经网络。对于决策树，Adaboost 分类使用的是 CART 分类树，而回归分体使用的是 CART 的回归树。

- 优点：
  1. 作为分类器时，分类的精度很高；
  2. 在 Adaboost 的框架下，可以使用各种分类回归模型来构建弱学习器，非常灵活。
  3. 作为简单的二元分类器时，构造简单，结果可以理解。
  4. 不容易发生过拟合
- 缺点：
  1. 对异常样本十分敏感，异常样本在迭代中可能会获得比较高的权重，影响最终的强学习期的准确性能。

------



#### 2.2 GBDT

&emsp;&emsp; GBDT —— 梯度提升树。

&emsp;&emsp; GBDT 也是集成学习中属于 Boosting 范畴的内容，确实和传统的 Adaboost 也有区别。GBDT 是使用前向分步算法进行迭代，组成最后强学习器的弱学习器也被限定为只能使用 CART 回归树模型，同事迭代思路也和之前的 Adaboost 不同。

&emsp;&emsp;在 GBDT 的迭代过程中没假设前一轮迭代得到的强学习器是 $f_{t-1}(x)$，且有损失函数 $L(y,f_{t-1}(x))$。那么，这一轮迭代的目标就是找到一个 CART 回归树模型的弱学习器 $h_t(x)$，使得本轮的损失的损失 $L(y,f_t(x))=L(y,f_{t-1}(x)+h_t(x))$ 最小。也就是说，本轮迭代要找到的决策树，要使得样本的损失尽量变得更小。

##### 2.2.1 负梯度拟合

&emsp;&emsp;现在的问题也就变成了如何才能拟合损失函数的问题。通常的做法是使用 **损失函数的负梯度来拟合本轮损失的近似值**，进而拟合成为一个 CART 回归树。第 $t$ 轮的第 $i$ 个样本的损失函数的负梯度可以表示为：
$$
r_{ti}=-\left[\frac{\partial L(y_i,f(x_i))}{\partial f(x_i)}\right]_{f(x)-f_{t-1}(x)}
$$
&emsp;&emsp;这样我们使用 $(x_i,r_{ti})\ \ \ (i=1,2,..,m)$，我们可以拟合一棵 CART 回归树，到了第 $t$ 棵回归树，其对应的叶节点区域 $R_{tj},j=1,2,...,J$，其中 $J$ 为叶子结点的个数。

&emsp;&emsp;针对每一个叶子结点里的样本，我们求出是损失函数最小，也就是拟合叶子结点最好的输出值 $c_{tj}$ 如下所示：
$$
c_{tj}=arg\ min_c\sum_{x_i\in R_{tj}}L(y_i,f_{t-1}(x_i)+c)
$$
这样我们也就得到了本轮的决策树拟合函数如下所示：
$$
h_t(x)=\sum_{j=1}^Jc_{tj}I(x\in R_{tj})
$$
从而本轮最终得到的强学习器的表达式如下所示：
$$
f_t(x)=f_{t-1}(x)+\sum_{j=1}^Jc_{tj}I(x\in R_{tj})
$$
通过使用损失函数的负梯度来进行拟合，找到了一种通用的用来拟合损失误差的方法，这样无论是分类问题还是回归问题，我么能通过其损失函数的负梯度进行拟合，就可以用 GBDT 来解决我们的分类回归问题。区别仅仅在于损失函数不同导致的负梯度不同而已。



##### 2.2.2 GBDT 的回归算法

&emsp;&emsp;一直一个训练数据集 $T={(x_1,y_1),(x_2,y_2),...,(x_N,y_N)},x_i\in\mathcal{X}\subseteq \textbf{R}^n$，其中 $\mathcal{X}$ 为输入空间，$y_i\in \mathcal{Y}\subseteq \textbf{R}$，其中 $\mathcal{Y}$ 是输出空间。

&emsp;&emsp;对于回归树来说，如果将输入空间 $\mathcal{X}$ 划分为 $J$ 个互不相交的区域 $R_1,R_2,...,R_J$，并且在每个区域上确定输出的常量 $c_j$，那么这个回归树可以表示为：
$$
T(x;\Theta)=\sum_{j=1}^Jc_jI(x\in R_j)
$$
其中，参数 $\Theta = \{(R_1,c_1),(R_2,c_2),...,(R_J,c_J),\}$ 表示树的区域划分和各个区域上的常数。$J$ 是回归树的复杂度，也就是叶节点的个数。

&emsp;&emsp;回归问题提升树使用以下前向分步算法：
$$
\begin{align}
f_0(x)&=0\\
f_m(x)&=f_{m-1}(x)+T(x;\Theta),\ \ \ m=1,2,...,M\\
f_M(x)&=\sum_{m=1}^MT(x;\Theta_m)
\end{align}
$$
在当前分布算法的第 $m$ 步，给定当前模型 $f_{m-1}(x)$，需要求解
$$
\hat\Theta_m=arg\ min_{\Theta_m}\ \sum_{i=1}^{N}L(y_i,f_{m-1}(x_i)+T(x_i;\Theta_m))
$$
从而进一步得到 $\hat\Theta_m$，也就是第 $m$ 棵树的参数。

&emsp;&emsp;当采用平方误差函数时，
$$
L(y,f(x))=(y-f(x))^2
$$
所以其损失变为：
$$
\begin{align}
L(y,f_{m-1}(x)+T(X;\Theta_m))&=[y-f_{m-1}(x)-T(x,\Theta_m)]^2\\
&=[r-T(x;\Theta_m)]^2
\end{align}
$$
其中，
$$
r=y-f_{m-1}(x)
$$
这是当前模型拟合数据的**残差（residual）**。所以，对于回归问题的提升树算法来说，只需要简单的拟合当前模型的残差，这样，算法是相当简单的。现在我们将回归问题的提升树算法叙述如下：



- **回归问题的提升树算法**

  - 输入：训练数据集  $T={(x_1,y_1),(x_2,y_2),...,(x_N,y_N)},x_i\in\mathcal{X}\subseteq \textbf{R}^n，y_i\in \mathcal{Y}\subseteq \textbf{R}$
  - 输出：提升树 $f_M(x)$

  1. 初始化 $f_0(x)=0$

  2. 对于 $m=1,2,...,M$

     - 计算残差：

     - $$
       r_{mi}=y_i-f_{m-1}(x_i),\ \ \ i=1,2,...,N
       $$

     - 拟合残差 $r_mi$ 学习一个回归树，得到 $T(x;\Theta_m)$

     - 更新 $f_m(x)=f_{m-1}(x)+T(x;\Theta_m)$

  3. 得到回归问题提升树：
     $$
     f_M(x)=\sum_{m=1}^MT(x;\Theta_m)
     $$
     ​